{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _api_tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the OpenAQ API\n",
    "\n",
    "The `openaq` api is an easy-to-use wrapper built around the [OpenAQ Api](https://docs.openaq.org/). Complete API documentation can be found on their website. \n",
    "\n",
    "There are no keys or rate limits (as of March 2017), so working with the API is straight forward. If building a website or app, you may want to just use the python wrapper and interact with the data in json format. However, the rest of this tutorial will assume you are interested in analyzing the data. To get more out of it, I recommend installing `seaborn` for manipulating the asthetics of plots, and working with data as DataFrames using `pandas`. For more information on these, check out the installation section of this documentation.\n",
    "\n",
    "From this point forward, I assume you have at least a basic knowledge of python and matplotlib. This documentation was built using the following versions of all packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas v0.23.4\n",
      "matplotlib v3.0.0\n",
      "seaborn v0.9.0\n",
      "openaq v1.1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import openaq\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set major seaborn asthetics\n",
    "sns.set(\"notebook\", style='ticks', font_scale=1.0)\n",
    "\n",
    "# Increase the quality of inline plots\n",
    "mpl.rcParams['figure.dpi']= 500\n",
    "\n",
    "print (\"pandas v{}\".format(pd.__version__))\n",
    "print (\"matplotlib v{}\".format(mpl.__version__))\n",
    "print (\"seaborn v{}\".format(sns.__version__))\n",
    "print (\"openaq v{}\".format(openaq.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAQ API\n",
    "\n",
    "The OpenAQ APi has only eight endpoints that we are interested in:\n",
    "\n",
    "  * cities: provides a simple listing of cities within the platforms\n",
    "  * countries: provides a simple listing of countries within the platform\n",
    "  * fetches: providing data about individual fetch operations that are used to populate data in the platform\n",
    "  * latest: provides the latest value of each available parameter for every location in the system\n",
    "  * locations: provides a list of measurement locations and their meta data\n",
    "  * measurements: provides data about individual measurements\n",
    "  * parameters: provides a simple listing of parameters within the platform\n",
    "  * sources: provides a list of data sources\n",
    "  \n",
    "For detailed documentation about each one in the context of this API wrapper, please check out the API documentation.\n",
    "\n",
    "### Your First Request\n",
    "\n",
    "Real quick, let's go ahead and initiate an instance of the `openaq.OpenAQ` class so we can begin looking at data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = openaq.OpenAQ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities\n",
    "\n",
    "The cities API endpoint lists the cities available within the platform. Results can be subselected by country and paginated to retrieve all results in the database. Let's start by performing a basic query with an increased limit (so we can get all of them) and return it as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2449 entries, 0 to 2448\n",
      "Data columns (total 4 columns):\n",
      "city         2449 non-null object\n",
      "count        2449 non-null int64\n",
      "country      2449 non-null object\n",
      "locations    2449 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "resp = api.cities(df=True, limit=10000)\n",
    "\n",
    "# display the first 10 rows\n",
    "resp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we retrieved 2400+ entries from the database. We can then take a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             city   count country  locations\n",
      "0                              Escaldes-Engordany   42206      AD          2\n",
      "1                                          unused    3238      AD          1\n",
      "2                                       Abu Dhabi   10633      AE          1\n",
      "3                                           Dubai    3626      AE          1\n",
      "4                                    Buenos Aires   14976      AR          4\n",
      "5                 Amt der Tiroler Landesregierung  113161      AT         19\n",
      "6                Gemeinde Wien, MA22 Umweltschutz  130328      AT         21\n",
      "7  Amt der Niederösterreichischen Landesregierung    1413      AT          3\n",
      "8    Amt der Oberösterreichischen Landesregierung    2828      AT          6\n",
      "9                                         Austria  121987      AT        174\n"
     ]
    }
   ],
   "source": [
    "print (resp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find out which ones are in India:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   city    count country  locations\n",
      "1219             Jaipur   258364      IN          9\n",
      "1220              Medak     2671      IN          1\n",
      "1221            Jodhpur   186822      IN          2\n",
      "1222              Delhi  1674023      IN         70\n",
      "1223              Satna    13907      IN          3\n",
      "1224           Gurugram    23513      IN          1\n",
      "1225               Agra   117957      IN          2\n",
      "1226          Mandideep    50439      IN          1\n",
      "1227          Hyderabad   697767      IN         16\n",
      "1228           Siliguri    15975      IN          3\n",
      "1229             Howrah   113197      IN          5\n",
      "1230             Rohtak   125266      IN          2\n",
      "1231         Aurangabad   135837      IN          2\n",
      "1232            Udaipur    58266      IN          2\n",
      "1233            Bhiwadi    43008      IN          2\n",
      "1234            Gurgaon   153776      IN          2\n",
      "1235           Chittoor     2013      IN          1\n",
      "1236          Singrauli    52661      IN          1\n",
      "1237           Tirupati   192438      IN          4\n",
      "1238     Chikkaballapur    21591      IN          1\n",
      "1239  Rajamahendravaram    69231      IN          4\n",
      "1240             Asanol     8549      IN          1\n",
      "1241           Durgapur    93705      IN          2\n",
      "1242               Kota    57860      IN          3\n",
      "1243            Kolkata   196593      IN          8\n",
      "1244            Asansol    26305      IN          3\n",
      "1245         Jorapokhar    54656      IN          2\n",
      "1246             Mumbai   352865      IN          4\n",
      "1247          Bengaluru   599799      IN         18\n",
      "1248          Ahmedabad    95457      IN          3\n",
      "...                 ...      ...     ...        ...\n",
      "1271              Thane   166236      IN          4\n",
      "1272          Moradabad    64315      IN          2\n",
      "1273             Kanpur   196257      IN          3\n",
      "1274             Nagpur    85216      IN          6\n",
      "1275          Panchkula   175213      IN          2\n",
      "1276            Baghpat    25300      IN          1\n",
      "1277              Hapur      686      IN          1\n",
      "1278           Varanasi   223295      IN          2\n",
      "1279             Khanna    32008      IN          1\n",
      "1280              NOIDA    13597      IN          1\n",
      "1281             Nashik   117546      IN          5\n",
      "1282           Ludhiana    82687      IN          2\n",
      "1283               Pali    62628      IN          3\n",
      "1284      Muzaffarnagar    19176      IN          1\n",
      "1285            Dhanbad        3      IN          1\n",
      "1286              Alwar    32531      IN          1\n",
      "1287           Hubballi     4404      IN          1\n",
      "1288          Amaravati    42179      IN          1\n",
      "1289               Pune   183909      IN          2\n",
      "1290          Pithampur    54275      IN          1\n",
      "1291         Kalaburagi      132      IN          1\n",
      "1292           Rupnagar    22019      IN          1\n",
      "1293             Haldia   146052      IN          3\n",
      "1294       Brajrajnagar    14943      IN          1\n",
      "1295          Jalandhar     9465      IN          1\n",
      "1296            Talcher    19248      IN          1\n",
      "1297              Patna   106631      IN          2\n",
      "1298              Dewas    52896      IN          1\n",
      "1299         Vijayawara    34902      IN          1\n",
      "1300        Bulandshahr    20840      IN          1\n",
      "\n",
      "[82 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (resp.query(\"country == 'IN'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! For the rest of the tutorial, we are going to focus on Delhi, India. Why? Well..because there are over 500,000 data points and my personal research is primarily in India. We will also take a look at some $SO_2$ data from Hawai'i later on (another great research locale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries\n",
    "\n",
    "Similar to the `cities` endpoint, the `countries` endpoint lists the countries available. The only parameters we have to play with are the limit and page number. If we want to grab them all, we can just up the limit to the maximum (10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cities code    count  locations       name\n",
      "0       2   AD    45444          3    Andorra\n",
      "1       1   AR    14976          4  Argentina\n",
      "2      19   AU  4493135        103  Australia\n",
      "3      16   AT  1521351        306    Austria\n",
      "4       1   BH    24239          1    Bahrain\n"
     ]
    }
   ],
   "source": [
    "res = api.countries(limit=10000, df=True)\n",
    "\n",
    "print (res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetches\n",
    "\n",
    "If you are interested in getting information pertaining to the individual data fetch operations, go ahead and use this endpoint. Most people won't need to use this. This API method does not allow the `df` parameter; if you would like it to be added, drop me a message.\n",
    "\n",
    "Otherwise, here is how you can access the json-formatted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'openaq-api',\n",
       " 'license': 'CC BY 4.0',\n",
       " 'website': 'https://docs.openaq.org/',\n",
       " 'page': 1,\n",
       " 'limit': 1,\n",
       " 'found': 123231,\n",
       " 'pages': 123231}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, resp = api.fetches(limit=1)\n",
    "\n",
    "# Print out the meta info\n",
    "resp['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "The `parameters` endpoint will provide a listing off all the parameters available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description    id   name  \\\n",
      "0                                       Black Carbon    bc     BC   \n",
      "1                                    Carbon Monoxide    co     CO   \n",
      "2                                   Nitrogen Dioxide   no2    NO2   \n",
      "3                                              Ozone    o3     O3   \n",
      "4  Particulate matter less than 10 micrometers in...  pm10   PM10   \n",
      "5  Particulate matter less than 2.5 micrometers i...  pm25  PM2.5   \n",
      "6                                     Sulfur Dioxide   so2    SO2   \n",
      "\n",
      "  preferredUnit  \n",
      "0         µg/m³  \n",
      "1           ppm  \n",
      "2           ppm  \n",
      "3           ppm  \n",
      "4         µg/m³  \n",
      "5         µg/m³  \n",
      "6           ppm  \n"
     ]
    }
   ],
   "source": [
    "res = api.parameters(df=True)\n",
    "\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "The `sources` endpoint will provide a list of the sources where the raw data came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'url': 'unused',\n",
       "   'adapter': 'unused',\n",
       "   'name': 'Dr. Raphael E. Arku and Colleagues',\n",
       "   'city': 'Accra',\n",
       "   'country': 'GH',\n",
       "   'description': 'Manual ingest of data from Dr. Raphael E. Arku and colleagues',\n",
       "   'sourceURL': 'https://www.ncbi.nlm.nih.gov/pubmed?term=Arku+RE%5BAuthor%5D+AND+Accra+air+pollution%5BAll+Fields%5D&cmd=DetailsSearch',\n",
       "   'contacts': ['info@openaq.org'],\n",
       "   'active': False}],\n",
       " [{'url': 'http://discomap.eea.europa.eu/map/fme/latest/',\n",
       "   'adapter': 'eea-direct',\n",
       "   'name': 'EEA Gibraltar',\n",
       "   'city': '',\n",
       "   'country': 'GI',\n",
       "   'description': 'Gibraltar data from UTD service',\n",
       "   'sourceURL': 'http://www.eea.europa.eu/themes/air/air-quality',\n",
       "   'contacts': ['info@openaq.org'],\n",
       "   'active': True}]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, resp = api.sources(df=False)\n",
    "\n",
    "# Print out the first one\n",
    "#res.ix[0]\n",
    "#pd.io.json.json_normalize(resp['results'])\n",
    "resp['results'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2c4b9b620a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/openaq/decorators.py\u001b[0m in \u001b[0;36mdecorated_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;31m# If there are any datetimes, make them datetimes!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/io/json/normalize.py\u001b[0m in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecord_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         if any([[isinstance(x, dict)\n\u001b[0;32m--> 198\u001b[0;31m                 for x in compat.itervalues(y)] for y in data]):\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;31m# naive normalization, this is idempotent for flat records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;31m# and potentially will inflate the data considerably for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/io/json/normalize.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecord_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         if any([[isinstance(x, dict)\n\u001b[0;32m--> 198\u001b[0;31m                 for x in compat.itervalues(y)] for y in data]):\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;31m# naive normalization, this is idempotent for flat records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;31m# and potentially will inflate the data considerably for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mitervalues\u001b[0;34m(obj, **kw)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "res = api.sources(df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locations\n",
    "\n",
    "The `locations` endpoint will return the list of measurement locations and their meta data. We can do quite a bit of querying with this one:\n",
    "\n",
    "Let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.locations(df=True)\n",
    "\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the first one\n",
    "res.ix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just want to grab the locations in Delhi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.locations(city='Delhi', df=True)\n",
    "\n",
    "\n",
    "res.ix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about just figuring out which locations in Delhi have $PM_{2.5}$ data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.locations(city='Delhi', parameter='pm25', df=True)\n",
    "\n",
    "res.ix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest\n",
    "\n",
    "Grab the latest data from a location or locations.\n",
    "\n",
    "What was the most recent $PM_{2.5}$ data in Delhi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.latest(city='Delhi', parameter='pm25', df=True)\n",
    "\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the most recent $SO_2$ data in Hawii?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.latest(city='Hilo', parameter='so2', df=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements\n",
    "\n",
    "Finally, the endpoint we've all been waiting for! Measurements allows you to grab all of the dataz! You can query on a whole bunhc of parameters listed in the API documentation. Let's dive in:\n",
    "\n",
    "Let's grab the past 10000 data points for $PM_{2.5}$ in Delhi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.measurements(city='Delhi', parameter='pm25', limit=10000, df=True)\n",
    "\n",
    "# Print out the statistics on a per-location basiss\n",
    "res.groupby(['location'])['value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we should be doing some serious data cleaning ;) Why don't we go ahead and plot all of these locations on a figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "for group, df in res.groupby('location'):\n",
    "    # Query the data to only get positive values and resample to hourly\n",
    "    _df = df.query(\"value >= 0.0\").resample('1h').mean()\n",
    "    \n",
    "    _df.value.plot(ax=ax, label=group)\n",
    "    \n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"$PM_{2.5}$  [$\\mu g m^{-3}$]\", fontsize=20)\n",
    "ax.set_xlabel(\"\")\n",
    "sns.despine(offset=5)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry too much about how ugly and uninteresting the plot above is...we'll take care of that in the next tutorial! Let's go ahead and look at the distribution of $PM_{2.5}$ values seen in Delhi by various sensors. This is the same data as above, but viewed in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14,7))\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    x='location', \n",
    "    y='value', \n",
    "    data=res.query(\"value >= 0.0\"), \n",
    "    fliersize=0, \n",
    "    palette='deep',\n",
    "    ax=ax)\n",
    "\n",
    "ax.set_ylim([0, 750])\n",
    "ax.set_ylabel(\"$PM_{2.5}\\;[\\mu gm^{-3}]$\", fontsize=18)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "sns.despine(offset=10)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remember from above, there was at least one location where many parameters were measured. Let's go ahead and look at that location and see if there is any correlation among parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.measurements(city='Delhi', location='Anand Vihar', limit=1000, df=True)\n",
    "\n",
    "# Which params do we have?\n",
    "res.parameter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for u in res.parameter.unique():\n",
    "    _df = res[res['parameter'] == u][['value']]\n",
    "    _df.columns = [u]\n",
    "    \n",
    "    # Merge the dataframes together\n",
    "    df = pd.merge(df, _df, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "# Get rid of rows where not all exist\n",
    "df.dropna(how='any', inplace=True)\n",
    "\n",
    "g = sns.PairGrid(df, diag_sharey=False)\n",
    "\n",
    "g.map_lower(sns.kdeplot, cmap='Blues_d')\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sns.kdeplot, lw=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kicks, let's go ahead and look at a timeseries of $SO_2$ data in Hawai'i. Quiz: What do you expect? Did you know that Hawai'i has a huge $SO_2$ problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.measurements(city='Hilo', parameter='so2', limit=10000, df=True)\n",
    "\n",
    "# Print out the statistics on a per-location basiss\n",
    "res.groupby(['location'])['value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "\n",
    "for group, df in res.groupby('location'):\n",
    "    # Query the data to only get positive values and resample to hourly\n",
    "    _df = df.query(\"value >= 0.0\").resample('6h').mean()\n",
    "    \n",
    "    # Convert from ppm to ppb\n",
    "    _df['value'] *= 1e3\n",
    "    \n",
    "    # Multiply the value by 1000 to get from ppm to ppb\n",
    "    _df.value.plot(ax=ax, label=group)\n",
    "    \n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"$SO_2 \\; [ppb]$\", fontsize=18)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "sns.despine(offset=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** These values are for 6h means. The local readings can actually get much, much higher (>5 ppm!) when looking at 1min data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
